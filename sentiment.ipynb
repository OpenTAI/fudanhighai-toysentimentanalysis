{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b35f8ee3-7187-4eec-84f8-c8ed5c71f506",
   "metadata": {},
   "source": [
    "# 情绪识别"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723b884-6831-479e-86b4-3484c502e059",
   "metadata": {},
   "source": [
    "## 调用需要使用的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "460a50c1-bcf2-4f22-baba-43854ba70e20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/remote-home/xieyong/conda/envs/GLM/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import train_test_split \n",
    "import pandas as pd\n",
    "import transformers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a120d7-8a70-4574-80f4-4e29a76ec2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f864b5b-6ed1-4975-b3e9-0d6b8c9938d8",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e695eff7-253b-42e3-94c5-45bd02cbebb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>文本</th>\n",
       "      <th>情绪标签</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>气死姐姐了，快二是阵亡了吗，尼玛，一个半小时过去了也没上车</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>妞妞啊，今天又承办了一个发文登记文号是126~嘻~么么哒~晚安哟</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>这里还值得注意另一个事实，就是张鞠存原有一个东溪草堂为其读书处。</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>这在前华约国家(尤其是东德)使用R-73的首次联合演习期间，被一些北约组织的飞行员所证实。</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TinyThief上wii了？！</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>每天都以紧张的心情工作，真的是太累，太不放松了，想要爆发一下</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>语文军，数学军，英语军，物理军，政治军，历史军，生物军，地理军，八科联军，侵犯我班，我班战败...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>我不是一个优秀的演员……不能微笑着旁观你们幸福。</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>当你变优秀时，你想要的都会来找你</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>累了一天！会宿舍听下我搞基新歌！在看看我段宜恩美图！心都被治愈了</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  文本      情绪标签\n",
       "0                      气死姐姐了，快二是阵亡了吗，尼玛，一个半小时过去了也没上车     angry\n",
       "1                   妞妞啊，今天又承办了一个发文登记文号是126~嘻~么么哒~晚安哟     happy\n",
       "2                   这里还值得注意另一个事实，就是张鞠存原有一个东溪草堂为其读书处。   neutral\n",
       "3      这在前华约国家(尤其是东德)使用R-73的首次联合演习期间，被一些北约组织的飞行员所证实。   neutral\n",
       "4                                   TinyThief上wii了？！  surprise\n",
       "5                     每天都以紧张的心情工作，真的是太累，太不放松了，想要爆发一下     angry\n",
       "6  语文军，数学军，英语军，物理军，政治军，历史军，生物军，地理军，八科联军，侵犯我班，我班战败...     angry\n",
       "7                           我不是一个优秀的演员……不能微笑着旁观你们幸福。       sad\n",
       "8                                   当你变优秀时，你想要的都会来找你     happy\n",
       "9                   累了一天！会宿舍听下我搞基新歌！在看看我段宜恩美图！心都被治愈了     happy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataset.csv').iloc[0:11000] #选取前11000条数据\n",
    "dataset.head(10) #查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb8cdc6f-ca6a-43ac-9104-ba8f235055dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>文本</th>\n",
       "      <th>情绪标签</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>气死姐姐了，快二是阵亡了吗，尼玛，一个半小时过去了也没上车</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>妞妞啊，今天又承办了一个发文登记文号是126~嘻~么么哒~晚安哟</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>这里还值得注意另一个事实，就是张鞠存原有一个东溪草堂为其读书处。</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>这在前华约国家(尤其是东德)使用R-73的首次联合演习期间，被一些北约组织的飞行员所证实。</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TinyThief上wii了？！</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              文本  情绪标签\n",
       "0                  气死姐姐了，快二是阵亡了吗，尼玛，一个半小时过去了也没上车     0\n",
       "1               妞妞啊，今天又承办了一个发文登记文号是126~嘻~么么哒~晚安哟     1\n",
       "2               这里还值得注意另一个事实，就是张鞠存原有一个东溪草堂为其读书处。     2\n",
       "3  这在前华约国家(尤其是东德)使用R-73的首次联合演习期间，被一些北约组织的飞行员所证实。     2\n",
       "4                               TinyThief上wii了？！     3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"情绪标签\"].replace({\n",
    "    \"angry\":0,\n",
    "    \"happy\":1,\n",
    "    \"neutral\":2,\n",
    "    \"surprise\":3,\n",
    "    \"fear\":4,\n",
    "    \"sad\":5\n",
    "},inplace=True)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8689ac2b-857b-4621-8a60-8eac307324ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "文本      0\n",
       "情绪标签    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c44ce466-224c-4630-a5b8-e8d6ad0eb95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "文本      0\n",
       "情绪标签    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dropna(axis=0, how='any',inplace=True) #处理缺失值\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c85761ca-5f54-4f84-854c-03d730fdbfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-chinese') #使用bert的tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a6050-43a8-47e2-9d69-d61567694bb5",
   "metadata": {},
   "source": [
    "#### 定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be4243b-e246-48d1-a10c-c414cea77e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self,dataset,tokenizer):\n",
    "        self.X = tokenizer(dataset['文本'].tolist(),truncation=True, padding=True)\n",
    "        self.Y = dataset['情绪标签'].astype('long').tolist()\n",
    "        \n",
    "        self.len = len(self.Y)\n",
    "        \n",
    "        self.input_ids = [torch.tensor(x).long() for x in self.X.input_ids]\n",
    "        self.token_type_ids = [torch.tensor(x).long() for x in self.X.token_type_ids]\n",
    "        self.attention_mask = [torch.tensor(x).long() for x in self.X.attention_mask]\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        data = {'features':{'input_ids': self.input_ids[index],\n",
    "                            'token_type_ids': self.token_type_ids[index],\n",
    "                            'attention_mask':self.attention_mask[index]\n",
    "                           },\n",
    "                'labels' : self.Y[index]\n",
    "               }\n",
    "        return data\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8c0296b-5086-4366-948c-da62ece55514",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet = MyDataset(dataset,tokenizer)\n",
    "# 将数据的80%作为训练集，剩下20%作为测试集\n",
    "train_data, test_data = train_test_split(DataSet, test_size = 0.2) \n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)#根据显卡的显存来选择，此处用的3090\n",
    "test_loader = DataLoader(test_data, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cedd256-a2c8-4b7e-b91a-b14752f15f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 建立模型，使用bert作为预训练模型，进行一些微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24186bd9-7b5d-4749-a958-2aaaf8ec7c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=6)\n",
    "lr = 1e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f7035-3153-4a33-8b78-c1c21167cfc6",
   "metadata": {},
   "source": [
    "### 开始训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0de39853-f335-4a5b-947d-24ef675bff0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 epoch start——\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [01:06,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 001 ] loss = 1.23002 , acc = 0.58507\n",
      "2 epoch start——\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [00:48,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 002 ] loss = 0.75096 , acc = 0.74438\n",
      "3 epoch start——\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [00:49,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 003 ] loss = 0.57242 , acc = 0.80929\n",
      "4 epoch start——\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [00:49,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 004 ] loss = 0.47094 , acc = 0.83945\n",
      "5 epoch start——\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [00:49,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 005 ] loss = 0.37475 , acc = 0.88244\n",
      "6 epoch start——\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [00:48,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 006 ] loss = 0.30016 , acc = 0.90610\n",
      "7 epoch start——\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [00:48,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 007 ] loss = 0.23708 , acc = 0.92973\n",
      "8 epoch start——\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [00:48,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 008 ] loss = 0.18849 , acc = 0.94467\n",
      "9 epoch start——\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [00:48,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 009 ] loss = 0.13877 , acc = 0.96403\n",
      "10 epoch start——\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [00:48,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 010 ] loss = 0.11111 , acc = 0.96981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    print(f\"{epoch+1} epoch start——\")\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "    for i, batch in tqdm(enumerate(train_loader)):\n",
    "        labels = batch['labels'].to(device)\n",
    "        input_ids = batch['features']['input_ids'].to(device)\n",
    "        token_type_ids = batch['features']['token_type_ids'].to(device)\n",
    "        attention_mask = batch['features']['attention_mask'].to(device)\n",
    "        out = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        l = out[0]\n",
    "        #l = loss(out,batch['labels'].to(device))\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        out[0].cpu()\n",
    "        acc = (out[1].argmax(dim=-1).cpu() == batch['labels']).float().mean()\n",
    "        train_loss.append(l.item())\n",
    "        train_accs.append(acc)\n",
    "    train_loss = sum(train_loss)/len(train_loss)\n",
    "    train_accs = sum(train_accs)/len(train_accs)\n",
    "    print(f\"[ Train | {epoch+1:03d} ] loss = {train_loss:.5f} , acc = {train_accs:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8667cd10-ca3e-455f-8b0b-62260641907b",
   "metadata": {},
   "source": [
    "### 测试模型的表现（明显有点过拟合了）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cbca704-cd4d-4e72-a21a-cf271b8e594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:04,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Train | 010 ] loss = 0.13033 , acc = 0.74711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "test_loss = []\n",
    "test_accs = []\n",
    "for i, batch in tqdm(enumerate(test_loader)):\n",
    "    with torch.no_grad():\n",
    "        labels = batch['labels'].to(device)\n",
    "        input_ids = batch['features']['input_ids'].to(device)\n",
    "        token_type_ids = batch['features']['token_type_ids'].to(device)\n",
    "        attention_mask = batch['features']['attention_mask'].to(device)\n",
    "        out = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "    acc = (out[1].argmax(dim=-1).cpu() == batch['labels']).float().mean()\n",
    "    test_loss.append(l.item())\n",
    "    test_accs.append(acc)\n",
    "test_loss = sum(test_loss)/len(test_loss)\n",
    "test_accs = sum(test_accs)/len(test_accs)\n",
    "print(f\"[ Train | {epoch+1:03d} ] loss = {test_loss:.5f} , acc = {test_accs:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b79c7af-4d29-4919-9d79-2571966cb30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'final_model.pth') #保存我们的整个模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6091d8-a1c3-4ee7-bf28-892d0557ea4c",
   "metadata": {},
   "source": [
    "### 用几个例子来看看我们模型的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ff7ee30-023f-4dc2-96d9-b3e7a73c6c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict_F(example,tokenizer,model):\n",
    "    labels = torch.tensor([1])\n",
    "    labels = labels.to(device)\n",
    "    token = tokenizer(example)\n",
    "    input_ids = torch.tensor(token.input_ids).to(device)\n",
    "    token_type_ids = torch.tensor(token.token_type_ids).to(device)\n",
    "    attention_mask = torch.tensor(token.attention_mask).to(device)\n",
    "    with torch.no_grad():\n",
    "        predict = model(input_ids, attention_mask=attention_mask, labels=labels)[1].argmax(dim=-1)\n",
    "    labels = [\"angry\",\"happy\",\"neutral\",\"surprise\",\"fear\",\"sad\"]\n",
    "    return labels[predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b2912e2-8f02-405f-893a-1279e1ead3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry\n"
     ]
    }
   ],
   "source": [
    "example = [\"为啥有人把我东西拿了，他在哪里！我要找到他！\"]\n",
    "pre = Predict_F(example,tokenizer,model)\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eded2401-4202-42f0-bf27-d9f39a03b80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n"
     ]
    }
   ],
   "source": [
    "example = [\"在复旦读书挺好的\"]\n",
    "pre = Predict_F(example,tokenizer,model)\n",
    "print(pre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
